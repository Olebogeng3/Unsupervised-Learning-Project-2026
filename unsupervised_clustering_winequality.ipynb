{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2763b380",
   "metadata": {},
   "source": [
    "# Unsupervised clustering on Wine Quality (Red)\n",
    "\n",
    "This notebook documents EDA, preprocessing, KMeans baseline training (silhouette-based k selection), and saving artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1682d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m pip install scikit-learn matplotlib seaborn joblib --quiet\n",
    "\n",
    "# Verify installations\n",
    "python - <<'PY'\n",
    "import sklearn, matplotlib, seaborn, joblib\n",
    "print('sklearn', sklearn.__version__)\n",
    "print('matplotlib', matplotlib.__version__)\n",
    "print('seaborn', seaborn.__version__)\n",
    "print('joblib', joblib.__version__)\n",
    "PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b3731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and notebook config\n",
    "%matplotlib inline\n",
    "import os\n",
    "import logging\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import joblib\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "RANDOM_SEED = 42\n",
    "ROOT = os.getcwd()\n",
    "DATA_PATH = os.path.join('Mock_student_packet_v4','winequality-red.csv')\n",
    "MODELS_DIR = 'models'\n",
    "RESULTS_DIR = 'results'\n",
    "for d in (MODELS_DIR, RESULTS_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print('ROOT:', ROOT)\n",
    "print('Data path:', DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933556f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "from typing import Tuple\n",
    "\n",
    "def load_wine(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, sep=';')\n",
    "    assert 'quality' in df.columns, 'Expected quality column'\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(df: pd.DataFrame) -> Tuple[np.ndarray, list]:\n",
    "    X = df.drop(columns=['quality']).values\n",
    "    feature_names = df.drop(columns=['quality']).columns.tolist()\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, feature_names, scaler\n",
    "\n",
    "\n",
    "# small unit test\n",
    "_example = pd.DataFrame({'a':[1,2], 'quality':[0,1]})\n",
    "try:\n",
    "    _ = preprocess(_example)\n",
    "    print('Preprocess smoke test: OK')\n",
    "except Exception as e:\n",
    "    print('Preprocess smoke test: FAILED', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bec722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and run EDA\n",
    "\n",
    "df = load_wine(DATA_PATH)\n",
    "print('Shape:', df.shape)\n",
    "print('\\nMissing values per column:\\n', df.isnull().sum())\n",
    "print('\\nQuality distribution:\\n', df['quality'].value_counts().sort_index())\n",
    "\n",
    "# Correlation\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Feature correlation')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'correlation.png'))\n",
    "print('Saved correlation heatmap to', os.path.join(RESULTS_DIR, 'correlation.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing, k selection, training, and saving artifacts\n",
    "\n",
    "X_scaled, feature_names, scaler = preprocess(df)\n",
    "\n",
    "# PCA for visualization\n",
    "pca = PCA(n_components=2, random_state=RANDOM_SEED)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# silhouette-based k selection\n",
    "scores = {}\n",
    "for k in range(2,9):\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_SEED, n_init=10)\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    scores[k] = silhouette_score(X_scaled, labels)\n",
    "\n",
    "best_k = max(scores, key=scores.get)\n",
    "print('Silhouette scores:', scores)\n",
    "print('Best k:', best_k)\n",
    "\n",
    "# fit final\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=RANDOM_SEED, n_init=10)\n",
    "kmeans.fit(X_scaled)\n",
    "labels = kmeans.predict(X_scaled)\n",
    "df['cluster'] = labels\n",
    "\n",
    "# save artifacts\n",
    "joblib.dump({'scaler':scaler, 'kmeans':kmeans, 'feature_names':feature_names}, os.path.join(MODELS_DIR, 'kmeans_pipeline.pkl'))\n",
    "joblib.dump(pca, os.path.join(MODELS_DIR, 'pca.pkl'))\n",
    "\n",
    "# plot clusters in PCA space\n",
    "plt.figure(figsize=(8,6))\n",
    "for cluster in sorted(df['cluster'].unique()):\n",
    "    idx = df['cluster'] == cluster\n",
    "    plt.scatter(X_pca[idx,0], X_pca[idx,1], label=f'Cluster {cluster}', alpha=0.6)\n",
    "plt.legend(); plt.title(f'KMeans clusters (k={best_k}) in PCA space')\n",
    "plt.xlabel('PCA1'); plt.ylabel('PCA2'); plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'cluster_pca.png'))\n",
    "print('Saved cluster image to', os.path.join(RESULTS_DIR, 'cluster_pca.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13087e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick evaluation and suggested next steps\n",
    "print('\\nCluster sizes:\\n', df['cluster'].value_counts().sort_index())\n",
    "print('\\nFinal silhouette score:', silhouette_score(X_scaled, df['cluster']))\n",
    "\n",
    "# Suggested next steps\n",
    "print('\\nSuggested next steps:')\n",
    "print('- Try GaussianMixture or DBSCAN to find non-convex clusters')\n",
    "print('- Experiment with feature selection or transformations for skewed features')\n",
    "print('- Compare clusters to quality labels and compute stats per cluster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbb8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary and how to load model\n",
    "print('Models saved to', MODELS_DIR)\n",
    "\n",
    "print('\\nExample: load model and predict on new data')\n",
    "print('''\n",
    "import joblib\n",
    "m = joblib.load('models/kmeans_pipeline.pkl')\n",
    "scaler = m['scaler']\n",
    "kmeans = m['kmeans']\n",
    "X_new_scaled = scaler.transform(X[:5])\n",
    "print(kmeans.predict(X_new_scaled))\n",
    "''')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
